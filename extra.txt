https://drive.google.com/drive/folders/1cbZA1iM8Jazun9OQ9TcKnwZL_T4AVC0b

def dice_coef(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.cast(y_pred, 'float32')
    intersection = K.sum(y_true_f * y_pred_f)
    union = K.sum(y_true_f) + K.sum(y_pred_f)
    return (2. * intersection + smooth) / (union + smooth)

def dice_loss(y_true, y_pred, smooth=1):
    return 1 - dice_coef(y_true, y_pred, smooth)

def bce_dice_loss(y_true, y_pred):
    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)

def bce_logdice_loss(y_true, y_pred):
    return binary_crossentropy(y_true, y_pred) - K.log(dice_coef(y_true, y_pred))

def true_positive_rate(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.cast(K.round(y_pred), 'float32')
    return K.sum(y_true_f * y_pred_f) / (K.sum(y_true_f) + K.epsilon())











import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import models, layers

# Define the UPSAMPLE_MODE and other constants
UPSAMPLE_MODE = 'DECONV'  # or 'SIMPLE' based on your requirement
EDGE_CROP = 0  # Adjust as necessary
NET_SCALING = None  # Adjust as necessary

# Conv2DTranspose upsampling
def upsample_conv(filters, kernel_size, strides, padding):
    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)

# Upsampling without Conv2DTranspose
def upsample_simple(filters, kernel_size, strides, padding):
    return layers.UpSampling2D(strides)

# Upsampling method choice
if UPSAMPLE_MODE == 'DECONV':
    upsample = upsample_conv
else:
    upsample = upsample_simple

# Load MobileNetV2 as encoder
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))  # Adjust input_shape as necessary
layer_names = [
    'block_1_expand_relu',   # 64x64
    'block_3_expand_relu',   # 32x32
    'block_6_expand_relu',   # 16x16
    'block_13_expand_relu',  # 8x8
    'block_16_project',      # 4x4
]

layers_dict = {name: base_model.get_layer(name).output for name in layer_names}

# Building the encoder using MobileNetV2
input_img = base_model.input

c1 = layers_dict['block_1_expand_relu']
c2 = layers_dict['block_3_expand_relu']
c3 = layers_dict['block_6_expand_relu']
c4 = layers_dict['block_13_expand_relu']
c5 = layers_dict['block_16_project']

# Building the decoder part of U-Net

u6 = upsample(64, (2, 2), strides=(2, 2), padding='same')(c5)
u6 = layers.concatenate([u6, c4])
c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u6)
c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c6)

u7 = upsample(32, (2, 2), strides=(2, 2), padding='same')(c6)
u7 = layers.concatenate([u7, c3])
c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u7)
c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c7)

u8 = upsample(16, (2, 2), strides=(2, 2), padding='same')(c7)
u8 = layers.concatenate([u8, c2])
c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(u8)
c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c8)

u9 = upsample(8, (2, 2), strides=(2, 2), padding='same')(c8)
u9 = layers.concatenate([u9, c1], axis=3)
c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(u9)
c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(c9)

d = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)
d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)
d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)

if NET_SCALING is not None:
    d = layers.UpSampling2D(NET_SCALING)(d)

mobilenetv2_unet = models.Model(inputs=[input_img], outputs=[d])

mobilenetv2_unet.summary()



import tensorflow as tf

# List available devices
devices = tf.config.list_physical_devices()
print("Available devices:", devices)

# Check if a GPU is available
if tf.config.list_physical_devices('GPU'):
    print("GPU is available")
else:
    print("GPU not available")





from tensorflow.keras import models, layers
from tensorflow.keras.applications import MobileNetV2

def create_mobilenet_encoder(input_shape):
    # Load MobileNetV2 with pre-trained ImageNet weights
    base_model = MobileNetV2(include_top=False, input_shape=input_shape, weights='imagenet')
    
    # Extract features at various stages to perform the skip connections later
    layer_names = [
        'block_1_expand_relu',   # 64x64
        'block_3_expand_relu',   # 32x32
        'block_6_expand_relu',   # 16x16
        'block_13_expand_relu',  # 8x8
        'block_16_project',      # 4x4
    ]
    layers = [base_model.get_layer(name).output for name in layer_names]

    # Create the feature extraction model
    down_stack = models.Model(inputs=base_model.input, outputs=layers)
    down_stack.trainable = False  # Freeze the layers to preserve pre-trained weights
    return down_stack

def upsample(filters, size, apply_dropout=False):
    initializer = tf.random_normal_initializer(0., 0.02)
    result = models.Sequential()
    result.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))
    result.add(layers.BatchNormalization())
    if apply_dropout:
        result.add(layers.Dropout(0.5))
    result.add(layers.ReLU())
    return result
def unet_model(output_channels, input_shape=(128, 128, 3)):
    inputs = layers.Input(shape=input_shape)
    encoder = create_mobilenet_encoder(input_shape)
    skips = encoder(inputs)
    x = skips[-1]
    skips = reversed(skips[:-1])

    # Upsampling and establishing the skip connections
    for up, skip in zip([512, 256, 128, 64], skips):
        x = upsample(up, 3)(x)
        concat = layers.Concatenate()
        x = concat([x, skip])

    # This is the last layer of the model
    last = layers.Conv2DTranspose(output_channels, 3, strides=2, padding='same')  #128x128 -> 256x256
    x = last(x)

    return models.Model(inputs=inputs, outputs=x)
from tensorflow.keras import backend as K
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

# Dice Coefficient
def dice_coef(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(K.cast(y_true, 'float32'))
    y_pred_f = K.flatten(K.cast(y_pred, 'float32'))
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

# Dice with BCE Loss
def dice_p_bce(y_true, y_pred):
    # Binary Cross-Entropy loss
    bce_loss = binary_crossentropy(y_true, y_pred)
    
    # Dice coefficient loss
    dice_loss = 1 - dice_coef(y_true, y_pred)
    
    # Combined loss with a weighting factor for dice loss
    alpha = 0.5  # Adjust the alpha to change the weight of dice loss in the overall loss function
    combo_loss = bce_loss + alpha * dice_loss
    
    return combo_loss

# Model Compilation
# Ensure your model is named correctly, here it is assumed to be `mobilenetv2_unet`
mobilenetv2_unet = unet_model(output_channels=1)  # Adjust output_channels based on your needs, e.g., 1 for binary segmentation
mobilenetv2_unet.compile(optimizer=Adam(learning_rate=1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef])

# Model Summary (optional)
mobilenetv2_unet.summary()


from tensorflow.keras import backend as K
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

# Dice Coefficient
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = K.flatten(K.cast(y_true, 'float32'))
    y_pred_f = K.flatten(K.cast(y_pred, 'float32'))
    intersection = K.sum(y_true_f * y_pred_f)
    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
    
    if K.any(K.is_nan(dice)):
        print("NaN detected in dice coefficient")
        print(f"y_true: {y_true_f}")
        print(f"y_pred: {y_pred_f}")
        print(f"intersection: {intersection}")
        print(f"dice: {dice}")
    
    return dice

# Dice with BCE Loss
def dice_p_bce(y_true, y_pred):
    # Binary Cross-Entropy loss
    bce_loss = binary_crossentropy(y_true, y_pred)
    
    if K.any(K.is_nan(bce_loss)):
        print("NaN detected in BCE loss")
        print(f"y_true: {y_true}")
        print(f"y_pred: {y_pred}")
        print(f"bce_loss: {bce_loss}")
    
    # Dice coefficient loss
    dice_loss = 1 - dice_coef(y_true, y_pred)
    
    if K.any(K.is_nan(dice_loss)):
        print("NaN detected in Dice loss")
        print(f"y_true: {y_true}")
        print(f"y_pred: {y_pred}")
        print(f"dice_loss: {dice_loss}")
    
    # Combined loss with a weighting factor for dice loss
    alpha = 0.5  # Adjust the alpha to change the weight of dice loss in the overall loss function
    combo_loss = bce_loss + alpha * dice_loss
    
    if K.any(K.is_nan(combo_loss)):
        print("NaN detected in combined loss")
        print(f"bce_loss: {bce_loss}")
        print(f"dice_loss: {dice_loss}")
        print(f"combo_loss: {combo_loss}")
    
    return combo_loss

mobilenetv2_unet.compile(optimizer=Adam(learning_rate=1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef])
