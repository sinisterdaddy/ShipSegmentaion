{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:28:01.246300Z","iopub.status.busy":"2022-10-17T21:28:01.245582Z","iopub.status.idle":"2022-10-17T21:28:03.501228Z","shell.execute_reply":"2022-10-17T21:28:03.500062Z","shell.execute_reply.started":"2022-10-17T21:28:01.246147Z"},"id":"duMa5oo7mFrI","trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from skimage.io import imread\n","from skimage.segmentation import mark_boundaries\n","from skimage.util import montage\n","from skimage.morphology import label\n","\n","import gc\n","gc.enable()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:28:03.503441Z","iopub.status.busy":"2022-10-17T21:28:03.503077Z","iopub.status.idle":"2022-10-17T21:28:03.508328Z","shell.execute_reply":"2022-10-17T21:28:03.507417Z","shell.execute_reply.started":"2022-10-17T21:28:03.503407Z"},"id":"q1XfqoRvmFrP","trusted":true},"outputs":[],"source":["# Train and test directories\n","train_image_dir = \"E:/train_v2\"\n","test_image_dir = \"E:/test_v2\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:28:03.510153Z","iopub.status.busy":"2022-10-17T21:28:03.509609Z","iopub.status.idle":"2022-10-17T21:28:05.186790Z","shell.execute_reply":"2022-10-17T21:28:05.185861Z","shell.execute_reply.started":"2022-10-17T21:28:03.510121Z"},"id":"_v7uprIWmFrP","outputId":"2a11ea28-c293-408e-acf2-7b4cc2fe319a","trusted":true},"outputs":[],"source":["# Getting into train directory\n","train_images = os.listdir(train_image_dir)\n","train_images.sort()\n","print(f\"Total of {len(train_images)} images in train directory.\\nHere is how first five train_images looks like:- {train_images[:5]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:28:09.303055Z","iopub.status.busy":"2022-10-17T21:28:09.301282Z","iopub.status.idle":"2022-10-17T21:28:10.613237Z","shell.execute_reply":"2022-10-17T21:28:10.611292Z","shell.execute_reply.started":"2022-10-17T21:28:09.303008Z"},"id":"zoIy1ed2mFrR","outputId":"58dfddd8-5ac8-417a-e644-e4424d88a4ae","trusted":true},"outputs":[],"source":["# Train ships segmented masks\n","masks = pd.read_csv('C:/Users/krish/Downloads/train_ship_segmentations_v2.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:28:12.705203Z","iopub.status.busy":"2022-10-17T21:28:12.704738Z","iopub.status.idle":"2022-10-17T21:28:12.718242Z","shell.execute_reply":"2022-10-17T21:28:12.716764Z","shell.execute_reply.started":"2022-10-17T21:28:12.705160Z"},"id":"dPjmkwHjmFrW","trusted":true},"outputs":[],"source":["# Define functions to do these tasks for all the training images\n","def rle_decode(mask_rle, shape=(768,768)):\n","    '''\n","    Input arguments -\n","    mask_rle: Mask of one ship in the train image\n","    shape: Output shape of the image array\n","    '''\n","    s = mask_rle.split()                                                               # Split the mask of each ship that is in RLE format\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]     # Get the start pixels and lengths for which image has ship\n","    ends = starts + lengths - 1                                                        # Get the end pixels where we need to stop\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)                                  # A 1D vec full of zeros of size = 768*768\n","    for lo, hi in zip(starts, ends):                                                   # For each start to end pixels where ship exists\n","        img[lo:hi+1] = 1                                                               # Fill those values with 1 in the main 1D vector\n","    '''\n","    Returns -\n","    Transposed array of the mask: Contains 1s and 0s. 1 for ship and 0 for background\n","    '''\n","    return img.reshape(shape).T                                                       \n","\n","def masks_as_image(in_mask_list):\n","    '''\n","    Input - \n","    in_mask_list: List of the masks of each ship in one whole training image\n","    '''\n","    all_masks = np.zeros((768, 768), dtype = np.int16)                                 # Creating 0s for the background\n","    for mask in in_mask_list:                                                          # For each ship rle data in the list of mask rle \n","        if isinstance(mask, str):                                                      # If the datatype is string\n","            all_masks += rle_decode(mask)                                              # Use rle_decode to create one mask for whole image\n","    '''\n","    Returns - \n","    Full mask of the training image whose RLE data has been passed as an input\n","    '''\n","    return np.expand_dims(all_masks, -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:28:15.686927Z","iopub.status.busy":"2022-10-17T21:28:15.686265Z","iopub.status.idle":"2022-10-17T21:28:15.829842Z","shell.execute_reply":"2022-10-17T21:28:15.829026Z","shell.execute_reply.started":"2022-10-17T21:28:15.686888Z"},"id":"h0BarNjlmFrX","outputId":"f5207375-1076-4703-81c7-b77c4f55f013","trusted":true},"outputs":[],"source":["'''Note that NaN values in the EncodedPixels are of float type and everything else is a string type'''   \n","\n","# Add a new feature to the masks data frame named as ship. If Encoded pixel in any row is a string, there is a ship else there isn't. \n","masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n","masks.head(9)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:28:15.832056Z","iopub.status.busy":"2022-10-17T21:28:15.831032Z","iopub.status.idle":"2022-10-17T21:28:16.022948Z","shell.execute_reply":"2022-10-17T21:28:16.021851Z","shell.execute_reply.started":"2022-10-17T21:28:15.832022Z"},"id":"iW_hlCevmFrX","outputId":"5c2f0605-a7f1-4018-c2db-e231138a817c","trusted":true},"outputs":[],"source":["# Making a new data frame with unique image ids where we are summing up the ship counts\n","unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index() \n","unique_img_ids.index+=1 # Incrimenting all the index by 1\n","unique_img_ids.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:28:16.024458Z","iopub.status.busy":"2022-10-17T21:28:16.024177Z","iopub.status.idle":"2022-10-17T21:28:16.092554Z","shell.execute_reply":"2022-10-17T21:28:16.091461Z","shell.execute_reply.started":"2022-10-17T21:28:16.024431Z"},"id":"aPaLVit8mFrX","outputId":"76a04e17-fa8c-4a27-fbdf-42f63a6fd876","trusted":true},"outputs":[],"source":["# Adding two new features to unique_img_ids data frame. If ship exists in image, val is 1 else 0. And it's vec form\n","unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n","unique_img_ids.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:28:16.095221Z","iopub.status.busy":"2022-10-17T21:28:16.094340Z","iopub.status.idle":"2022-10-17T21:35:38.975476Z","shell.execute_reply":"2022-10-17T21:35:38.974362Z","shell.execute_reply.started":"2022-10-17T21:28:16.095174Z"},"id":"ETbI2Byss5zG","outputId":"ed08ef0c-db14-46ed-8fab-30af19a35c3b","trusted":true},"outputs":[],"source":["# Check the size of the files. Will take some time to run as there are loads of files!!!\n","unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: os.stat(os.path.join(train_image_dir, c_img_id)).st_size/1024)\n","'''os.stat is used to get status of the specified path. Here, st_size represents size of the file in bytes. Converting it into kB!'''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:38.978015Z","iopub.status.busy":"2022-10-17T21:35:38.977300Z","iopub.status.idle":"2022-10-17T21:35:39.001339Z","shell.execute_reply":"2022-10-17T21:35:39.000141Z","shell.execute_reply.started":"2022-10-17T21:35:38.977969Z"},"id":"dh7Z40aIs5zH","outputId":"c86e02f4-f0af-4561-d8de-e9d827cbd48b","trusted":true},"outputs":[],"source":["# We can get rid of any images whose size is less than 35 Kb. As some of the files are corrupted! \n","unique_img_ids[unique_img_ids.file_size_kb<35].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:39.654530Z","iopub.status.busy":"2022-10-17T21:35:39.654081Z","iopub.status.idle":"2022-10-17T21:35:39.678190Z","shell.execute_reply":"2022-10-17T21:35:39.677117Z","shell.execute_reply.started":"2022-10-17T21:35:39.654499Z"},"id":"Vcom6VhkmFrY","outputId":"022411aa-a97c-4e5d-a31d-02ea013dd24b","trusted":true},"outputs":[],"source":["# Keep the files whose size > 35 kB\n","unique_img_ids = unique_img_ids[unique_img_ids.file_size_kb > 35]\n","unique_img_ids.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:39.680310Z","iopub.status.busy":"2022-10-17T21:35:39.679850Z","iopub.status.idle":"2022-10-17T21:35:39.704185Z","shell.execute_reply":"2022-10-17T21:35:39.703307Z","shell.execute_reply.started":"2022-10-17T21:35:39.680259Z"},"id":"DfJCvsCHmFrY","outputId":"43d5f845-b7a9-4c85-861d-4eb5dd059880","trusted":true},"outputs":[],"source":["# Also, retrive the old masks data frame\n","masks.drop(['ships'], axis=1, inplace=True)\n","masks.index+=1 \n","masks.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:39.706334Z","iopub.status.busy":"2022-10-17T21:35:39.705539Z","iopub.status.idle":"2022-10-17T21:35:39.927959Z","shell.execute_reply":"2022-10-17T21:35:39.926718Z","shell.execute_reply.started":"2022-10-17T21:35:39.706274Z"},"id":"bbQHbyzxmFrY","trusted":true},"outputs":[],"source":["# Train - Test split\n","from sklearn.model_selection import train_test_split                   \n","train_ids, valid_ids = train_test_split(unique_img_ids, test_size = 0.3, stratify = unique_img_ids['ships'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:39.930255Z","iopub.status.busy":"2022-10-17T21:35:39.929890Z","iopub.status.idle":"2022-10-17T21:35:40.221975Z","shell.execute_reply":"2022-10-17T21:35:40.220952Z","shell.execute_reply.started":"2022-10-17T21:35:39.930221Z"},"id":"mObH089jmFrZ","trusted":true},"outputs":[],"source":["# Create train data frame\n","train_df = pd.merge(masks, train_ids)\n","\n","# Create test data frame\n","valid_df = pd.merge(masks, valid_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:40.224557Z","iopub.status.busy":"2022-10-17T21:35:40.224102Z","iopub.status.idle":"2022-10-17T21:35:40.231734Z","shell.execute_reply":"2022-10-17T21:35:40.230610Z","shell.execute_reply.started":"2022-10-17T21:35:40.224516Z"},"id":"5Po1UEcGmFrZ","outputId":"0bbb1cb4-603c-43d2-97a6-a2647072d42a","trusted":true},"outputs":[],"source":["print(\"There are ~\")\n","print(train_df.shape[0], 'training masks,')\n","print(valid_df.shape[0], 'validation masks.')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:40.518655Z","iopub.status.busy":"2022-10-17T21:35:40.518255Z","iopub.status.idle":"2022-10-17T21:35:40.598299Z","shell.execute_reply":"2022-10-17T21:35:40.597106Z","shell.execute_reply.started":"2022-10-17T21:35:40.518626Z"},"id":"GW1DYwrfmFre","trusted":true},"outputs":[],"source":["# Clipping the max value of grouped_ship_count to be 7, minimum to be 0\n","train_df['grouped_ship_count'] = train_df.ships.map(lambda x: (x+1)//2).clip(0,7)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:40.600757Z","iopub.status.busy":"2022-10-17T21:35:40.599970Z","iopub.status.idle":"2022-10-17T21:35:40.611765Z","shell.execute_reply":"2022-10-17T21:35:40.610553Z","shell.execute_reply.started":"2022-10-17T21:35:40.600709Z"},"id":"QHic4kjdmFre","outputId":"900177b5-aff2-4aba-ab08-fc1124e93356","trusted":true},"outputs":[],"source":["# Check\n","train_df.grouped_ship_count.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:40.660800Z","iopub.status.busy":"2022-10-17T21:35:40.660413Z","iopub.status.idle":"2022-10-17T21:35:40.667078Z","shell.execute_reply":"2022-10-17T21:35:40.665820Z","shell.execute_reply.started":"2022-10-17T21:35:40.660744Z"},"id":"yvk146BImFre","trusted":true},"outputs":[],"source":["# Random Under-Sampling ships\n","def sample_ships(in_df, base_rep_val=1500):\n","    '''\n","    Input Args:\n","    in_df - dataframe we want to apply this function\n","    base_val - random sample of this value to be taken from the data frame\n","    '''\n","    if in_df['ships'].values[0]==0:                                                 \n","        return in_df.sample(base_rep_val//3)  # Random 1500//3 = 500 samples taken whose ship count is 0 in an image \n","    else:                                 \n","        return in_df.sample(base_rep_val)    # Random 1500 samples taken whose ship count is not 0 in an image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:40.668967Z","iopub.status.busy":"2022-10-17T21:35:40.668525Z","iopub.status.idle":"2022-10-17T21:35:40.728842Z","shell.execute_reply":"2022-10-17T21:35:40.727664Z","shell.execute_reply.started":"2022-10-17T21:35:40.668931Z"},"id":"Sh2SgP5lmFrf","outputId":"52adb1b2-7c42-4e5a-9275-dc61f8aee600","trusted":true},"outputs":[],"source":["# Creating groups of ship counts and applying the sample_ships functions to randomly undersample the ships\n","balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\n","balanced_train_df.grouped_ship_count.value_counts() # In each group we have total of 1500 ships except 0 as we have decreased it even more to 500"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:40.730294Z","iopub.status.busy":"2022-10-17T21:35:40.730006Z","iopub.status.idle":"2022-10-17T21:35:40.751409Z","shell.execute_reply":"2022-10-17T21:35:40.750461Z","shell.execute_reply.started":"2022-10-17T21:35:40.730268Z"},"id":"6SERf32pmFrf","outputId":"612c6483-a49f-4cf1-d6c2-cd3a5486bfb6","trusted":true},"outputs":[],"source":["# Explaining what we just did if still not clear\n","for i in range(8):\n","    df_val_counts = balanced_train_df[balanced_train_df.grouped_ship_count==i].ships.value_counts()\n","    print(f\"Data frame for grouped ship count = {i}:-\\n{df_val_counts}\\nSum of Values:- {df_val_counts.values.sum()}\\n\\n\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -U -q segmentation-models\n","!pip install -q tensorflow==2.2.1\n","!pip install -q keras==2.5\n","import os\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:41.325810Z","iopub.status.busy":"2022-10-17T21:35:41.325319Z","iopub.status.idle":"2022-10-17T21:35:41.332463Z","shell.execute_reply":"2022-10-17T21:35:41.331231Z","shell.execute_reply.started":"2022-10-17T21:35:41.325748Z"},"id":"YnVyTCqUmFrf","trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from skimage.io import imread\n","from skimage.util import montage\n","from skimage.segmentation import mark_boundaries\n","\n","from tensorflow.keras import models, layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","from keras.losses import binary_crossentropy\n","from tensorflow.keras.optimizers import Adam\n","import keras.backend as K\n","\n","import segmentation_models as sm\n","\n","# Parameters\n","BATCH_SIZE = 4\n","EDGE_CROP = 16\n","NB_EPOCHS = 100\n","GAUSSIAN_NOISE = 0.1\n","UPSAMPLE_MODE = 'SIMPLE'\n","NET_SCALING = None\n","IMG_SCALING = (1, 1)\n","VALID_IMG_COUNT = 400\n","MAX_TRAIN_STEPS = 20\n","BACKBONE = 'resnet50'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:41.334548Z","iopub.status.busy":"2022-10-17T21:35:41.334116Z","iopub.status.idle":"2022-10-17T21:35:41.346158Z","shell.execute_reply":"2022-10-17T21:35:41.344706Z","shell.execute_reply.started":"2022-10-17T21:35:41.334506Z"},"id":"_l69s0W_mFrf","trusted":true},"outputs":[],"source":["# Image and Mask Generator\n","def make_image_gen(in_df, batch_size = BATCH_SIZE):\n","    '''\n","    Inputs -\n","    in_df - data frame on which the function will be applied\n","    batch_size - number of training examples in one iteration\n","    '''\n","    all_batches = list(in_df.groupby('ImageId'))                             # Group ImageIds and create list of that dataframe\n","    out_rgb = []                                                             # Image list\n","    out_mask = []                                                            # Mask list\n","    while True:                                                              # Loop for every data\n","        np.random.shuffle(all_batches)                                       # Shuffling the data\n","        for c_img_id, c_masks in all_batches:                                # For img_id and msk_rle in all_batches\n","            rgb_path = os.path.join(train_image_dir, c_img_id)               # Get the img path\n","            c_img = imread(rgb_path)                                         # img array\n","            c_mask = masks_as_image(c_masks['EncodedPixels'].values)         # Create mask of rle data for each ship in an img\n","            out_rgb += [c_img]                                               # Append the current img in the out_rgb / img list\n","            out_mask += [c_mask]                                             # Append the current mask in the out_mask / mask list\n","            if len(out_rgb)>=batch_size:                                     # If length of list is more or equal to batch size then\n","                yield np.stack(out_rgb)/255.0, np.stack(out_mask)            # Yeild the scaled img array (b/w 0 and 1) and mask array (0 for bg and 1 for ship)\n","                out_rgb, out_mask=[], []                                     # Empty the lists to create another batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:41.348304Z","iopub.status.busy":"2022-10-17T21:35:41.347903Z","iopub.status.idle":"2022-10-17T21:35:42.245930Z","shell.execute_reply":"2022-10-17T21:35:42.244847Z","shell.execute_reply.started":"2022-10-17T21:35:41.348269Z"},"id":"LrGDDsHvmFrf","outputId":"df2fec31-16f5-4777-ade6-c3e79a8eabf6","trusted":true},"outputs":[],"source":["# Generate train data \n","train_gen = make_image_gen(balanced_train_df)\n","\n","# Image and Mask\n","train_x, train_y = next(train_gen)\n","\n","# Print the summary\n","print(f\"train_x ~\\nShape: {train_x.shape}\\nMin value: {train_x.min()}\\nMax value: {train_x.max()}\")\n","print(f\"\\ntrain_y ~\\nShape: {train_y.shape}\\nMin value: {train_y.min()}\\nMax value: {train_y.max()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:42.247459Z","iopub.status.busy":"2022-10-17T21:35:42.247118Z","iopub.status.idle":"2022-10-17T21:35:45.391737Z","shell.execute_reply":"2022-10-17T21:35:45.390841Z","shell.execute_reply.started":"2022-10-17T21:35:42.247429Z"},"id":"YeeCgg_PmFrf","outputId":"dca020dc-5290-4100-b206-6f277a1e0506","trusted":true},"outputs":[],"source":["# Visulaising train batch\n","montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n","batch_rgb = montage_rgb(train_x)                                                   # Create montage of img\n","batch_seg = montage(train_y[:, :, :, 0])                                           # Create montafe of msk\n","batch_overlap = mark_boundaries(batch_rgb, batch_seg.astype(int))                  # Create bounding box around ships in img\n","titles = [\"Images\", \"Segmentations\", \"Bounding Boxes on ships in Images\"]          # Titles for subplot\n","colors = ['g', 'm', 'b']                                                           # Colors to be used for title\n","display = [batch_rgb, batch_seg, batch_overlap]                                    # What to display in subplot\n","plt.figure(figsize=(25,10))                                                        # Generate figure \n","for i in range(3):                                                                 # For i = 0, 1, 2, 3                           \n","    plt.subplot(1, 3, i+1)                                                         # Create subplot\n","    plt.imshow(display[i])                                                         # Display \n","    plt.title(titles[i], fontsize = 18, color = colors[i])                         # Title \n","    plt.axis('off')                                                                # Turn off the axis\n","plt.suptitle(\"Batch Visualizations\", fontsize = 20, color = 'r', weight = 'bold')  # Add suptitle\n","plt.tight_layout()                                                                 # Layout for subplot"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:35:45.393985Z","iopub.status.busy":"2022-10-17T21:35:45.393123Z","iopub.status.idle":"2022-10-17T21:36:02.704249Z","shell.execute_reply":"2022-10-17T21:36:02.703028Z","shell.execute_reply.started":"2022-10-17T21:35:45.393950Z"},"id":"aUXAhwWKmFrg","outputId":"4c4f0973-9452-495c-b696-b0dbe07debcd","trusted":true},"outputs":[],"source":["# Prepare validation data\n","valid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\n","print(f\"valid_x ~\\nShape: {valid_x.shape}\\nMin value: {valid_x.min()}\\nMax value: {valid_x.max()}\")\n","print(f\"\\nvalid_y ~\\nShape: {valid_y.shape}\\nMin value: {valid_y.min()}\\nMax value: {valid_y.max()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:36:02.706325Z","iopub.status.busy":"2022-10-17T21:36:02.705900Z","iopub.status.idle":"2022-10-17T21:36:08.166027Z","shell.execute_reply":"2022-10-17T21:36:08.164852Z","shell.execute_reply.started":"2022-10-17T21:36:02.706283Z"},"id":"Ru71AFFwmFrg","trusted":true},"outputs":[],"source":["# Augmenting Data using ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Preparing image data generator arguments\n","dg_args = dict(rotation_range = 15,            # Degree range for random rotations\n","               horizontal_flip = True,         # Randomly flips the inputs horizontally\n","               vertical_flip = True,           # Randomly flips the inputs vertically\n","               data_format = 'channels_last')  # channels_last refer to (batch, height, width, channels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:36:08.168830Z","iopub.status.busy":"2022-10-17T21:36:08.167931Z","iopub.status.idle":"2022-10-17T21:36:08.179997Z","shell.execute_reply":"2022-10-17T21:36:08.178812Z","shell.execute_reply.started":"2022-10-17T21:36:08.168756Z"},"id":"HQvlfWvjmFrg","trusted":true},"outputs":[],"source":["image_gen = ImageDataGenerator(**dg_args)\n","label_gen = ImageDataGenerator(**dg_args)\n","\n","def create_aug_gen(in_gen, seed = None):\n","    '''\n","    Takes in -\n","    in_gen - train data generator, seed value\n","    '''\n","    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))  # Randomly assign seed value if not provided\n","    for in_x, in_y in in_gen:                                                    # For imgs and msks in train data generator\n","        seed = 12                                                                # Seed value for imgs and msks must be same else augmentation won't be same\n","        \n","        # Create augmented imgs\n","        g_x = image_gen.flow(255*in_x,                                           # Inverse scaling on imgs for augmentation                                       \n","                             batch_size = in_x.shape[0],                         # batch_size = 3\n","                             seed = seed,                                        # Seed\n","                             shuffle=True)                                       # Shuffle the data\n","        \n","        # Create augmented masks\n","        g_y = label_gen.flow(in_y,\n","                             batch_size = in_x.shape[0],                       \n","                             seed = seed,                                         \n","                             shuffle=True)                                       \n","        \n","        '''Yeilds - augmented scaled imgs and msks array'''\n","        yield next(g_x)/255.0, next(g_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:36:08.182676Z","iopub.status.busy":"2022-10-17T21:36:08.182131Z","iopub.status.idle":"2022-10-17T21:36:09.438852Z","shell.execute_reply":"2022-10-17T21:36:09.438051Z","shell.execute_reply.started":"2022-10-17T21:36:08.182560Z"},"id":"YChZ_zOqmFrg","outputId":"a941718e-7822-48f5-ee72-d37771ecec6a","trusted":true},"outputs":[],"source":["# Augment the train data\n","cur_gen = create_aug_gen(train_gen, seed = 42)\n","t_x, t_y = next(cur_gen)\n","print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n","print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Preprocess input for ResNet50\n","preprocess_input = sm.get_preprocessing(BACKBONE)\n","train_x = preprocess_input(train_x)\n","valid_x = preprocess_input(valid_x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# BACKBONE = 'resnet50'\n","# resnet50_unet = sm.Unet(BACKBONE, input_shape=(None, None, 3), encoder_weights='imagenet', classes=1, activation='sigmoid')\n","# resnet50_unet.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:36:12.358523Z","iopub.status.busy":"2022-10-17T21:36:12.357993Z","iopub.status.idle":"2022-10-17T21:36:12.600209Z","shell.execute_reply":"2022-10-17T21:36:12.599354Z","shell.execute_reply.started":"2022-10-17T21:36:12.358464Z"},"id":"H2GlhnR-mFrh","outputId":"0a87d09b-5b3a-45d2-fa71-7afdf43b8721","trusted":true},"outputs":[],"source":["gc.collect() # Block all the garbage that has been generated"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:36:12.602462Z","iopub.status.busy":"2022-10-17T21:36:12.601329Z","iopub.status.idle":"2022-10-17T21:36:12.967955Z","shell.execute_reply":"2022-10-17T21:36:12.966803Z","shell.execute_reply.started":"2022-10-17T21:36:12.602420Z"},"id":"Wb1YIcPTmFrh","outputId":"3b67adaa-872e-4943-c435-79b23331b253","trusted":true},"outputs":[],"source":["from keras import models, layers\n","from keras.applications import ResNet50\n","from keras.layers import BatchNormalization\n","\n","# Define upsampling functions\n","def upsample_conv(filters, kernel_size, strides, padding):\n","    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n","\n","# Set upsampling mode\n","upsample = upsample_conv\n","\n","# Input layer\n","input_img = layers.Input((768, 768, 3), name='RGB_Input')\n","\n","# Load pre-trained ResNet50\n","resnet_base = ResNet50(weights='imagenet', include_top=False, input_tensor=input_img)\n","\n","# Extract layers for skip connections\n","c1 = resnet_base.get_layer('conv1_relu').output\n","c2 = resnet_base.get_layer('conv2_block3_out').output\n","c3 = resnet_base.get_layer('conv3_block4_out').output\n","c4 = resnet_base.get_layer('conv4_block6_out').output\n","c5 = resnet_base.get_layer('conv5_block3_out').output\n","\n","# Decoder (Upsampling Path)\n","u6 = upsample(512, (2, 2), strides=(2, 2), padding='same')(c5)\n","u6 = layers.concatenate([u6, c4])\n","c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n","c6 = BatchNormalization()(c6)\n","c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n","c6 = BatchNormalization()(c6)\n","\n","u7 = upsample(256, (2, 2), strides=(2, 2), padding='same')(c6)\n","u7 = layers.concatenate([u7, c3])\n","c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n","c7 = BatchNormalization()(c7)\n","c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n","c7 = BatchNormalization()(c7)\n","\n","u8 = upsample(128, (2, 2), strides=(2, 2), padding='same')(c7)\n","u8 = layers.concatenate([u8, c2])\n","c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n","c8 = BatchNormalization()(c8)\n","c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n","c8 = BatchNormalization()(c8)\n","\n","u9 = upsample(64, (2, 2), strides=(2, 2), padding='same')(c8)\n","u9 = layers.concatenate([u9, c1])\n","c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n","c9 = BatchNormalization()(c9)\n","c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n","c9 = BatchNormalization()(c9)\n","\n","# Ensure the final upsampling restores the original input size\n","u10 = upsample(32, (2, 2), strides=(2, 2), padding='same')(c9)\n","c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u10)\n","c10 = BatchNormalization()(c10)\n","c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c10)\n","c10 = BatchNormalization()(c10)\n","\n","# Output layer\n","output_layer = layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\n","\n","# Build the model\n","resnet50_unet = models.Model(inputs=[input_img], outputs=[output_layer])\n","\n","# Print the model summary\n","resnet50_unet.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:36:12.969981Z","iopub.status.busy":"2022-10-17T21:36:12.969608Z","iopub.status.idle":"2022-10-17T21:36:12.993715Z","shell.execute_reply":"2022-10-17T21:36:12.992604Z","shell.execute_reply.started":"2022-10-17T21:36:12.969947Z"},"id":"esAWI3D_mFrh","trusted":true},"outputs":[],"source":["# Compute dice coefficient, loss with BCE and compile the model\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.losses import binary_crossentropy\n","from tensorflow.keras.optimizers import Adam\n","\n","# Dice Coefficient\n","import tensorflow.keras.backend as K\n","\n","def dice_coef(y_true, y_pred, smooth=1):\n","    y_true_f = K.flatten(K.cast(y_true, 'float32'))\n","    y_pred_f = K.flatten(K.cast(y_pred, 'float32'))\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","\n","# Dice with BCE Loss\n","def dice_p_bce(y_true, y_pred):\n","    # Binary Cross-Entropy loss\n","    bce_loss = binary_crossentropy(y_true, y_pred)\n","    \n","    # Dice coefficient loss\n","    dice_loss = 1 - dice_coef(y_true, y_pred)\n","    \n","    # Combined loss\n","    alpha = 1e-3\n","    combo_loss = bce_loss + alpha * dice_loss\n","    \n","    return combo_loss\n","# Compile the model\n","resnet50_unet.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-17T21:36:12.995696Z","iopub.status.busy":"2022-10-17T21:36:12.995175Z","iopub.status.idle":"2022-10-17T21:36:13.004891Z","shell.execute_reply":"2022-10-17T21:36:13.003652Z","shell.execute_reply.started":"2022-10-17T21:36:12.995654Z"},"id":"Oy1k7BWEmFrh","trusted":true},"outputs":[],"source":["# Preparing Callbacks\n","# Preparing Callbacks\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n","\n","# Best model weights\n","weight_path = \"{}_weights.best.weights.h5\".format('resnet50_unet')\n","print(type(weight_path))\n","# Monitor validation dice coeff and save the best model weights\n","checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n","                             save_best_only=True, mode='max', save_weights_only=True)\n","\n","# Reduce Learning Rate on Plateau\n","reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n","                                   patience=3, verbose=1, mode='max', \n","                                   min_delta=0.0001, cooldown=2, min_lr=1e-6)\n","\n","# Stop training once there is no improvement seen in the model\n","early = EarlyStopping(monitor=\"val_dice_coef\", mode=\"max\", patience=10)\n","\n","# Callbacks ready\n","callbacks_list = [checkpoint, early, reduceLROnPlat]\n","print([type(callback) for callback in callbacks_list])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QNJtGrRmFrj","trusted":true},"outputs":[],"source":["# # Finalizing steps per epoch\n","step_count = min(MAX_TRAIN_STEPS, balanced_train_df.shape[0] // BATCH_SIZE)\n","\n","# Final augmented data being used in training\n","aug_gen = create_aug_gen(make_image_gen(balanced_train_df))\n","\n","# Save loss history while training\n","loss_history = [resnet50_unet.fit(\n","                                        aug_gen, \n","                                        steps_per_epoch=step_count, \n","                                        epochs=NB_EPOCHS, \n","                                        validation_data=(valid_x, valid_y),\n","                                        callbacks=callbacks_list,\n","                                        )]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-10-17T21:36:15.259978Z","iopub.status.idle":"2022-10-17T21:36:15.261264Z","shell.execute_reply":"2022-10-17T21:36:15.260977Z","shell.execute_reply.started":"2022-10-17T21:36:15.260945Z"},"id":"puTYhSN0mFrj","trusted":true},"outputs":[],"source":["# Save the weights to load it later for test data \n","# resnet50_unet.load_weights(\"C:/Users/krish/Downloads/resnet50_unet_weights.best.weights.h5\")\n","resnet50_unet.save('resnet50_unet.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.models import load_model\n","import tensorflow as tf\n","import cv2\n","\n","# Define image dimensions and path to the test directory\n","IMG_HEIGHT = 768  # Change this to your image height\n","IMG_WIDTH = 768   # Change this to your image width\n","TEST_DIR = r'E:/test_v2'  # Use raw string literal for Windows paths\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix\n","import seaborn as sns\n","\n","# Function to plot ROC curve\n","def plot_roc_curve(y_true, y_pred):\n","    fpr, tpr, _ = roc_curve(y_true, y_pred)\n","    roc_auc = roc_auc_score(y_true, y_pred)\n","    \n","    plt.figure()\n","    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","y_true = valid_y.flatten()\n","y_pred = resnet50_unet.predict(valid_x).flatten()\n","# Plot ROC curve\n","plot_roc_curve(y_true, y_pred)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to plot Precision-Recall curve\n","def plot_precision_recall_curve(y_true, y_pred):\n","    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n","    \n","    plt.figure()\n","    plt.plot(recall, precision, color='b', lw=2, label='Precision-Recall curve')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Precision-Recall Curve')\n","    plt.legend(loc=\"lower left\")\n","    plt.show()\n","\n","# Function to plot Confusion Matrix\n","def plot_confusion_matrix(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred > 0.5)\n","    \n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n","    plt.ylabel('Actual')\n","    plt.xlabel('Predicted')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# Flatten predictions and true labels\n","y_true = valid_y.flatten()\n","y_pred = resnet50_unet.predict(valid_x).flatten()\n","plot_precision_recall_curve(y_true, y_pred)\n","\n","# Plot Confusion Matrix\n","plot_confusion_matrix(y_true, y_pred)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the trained model with custom objects\n","custom_objects = {'dice_coef': dice_coef}\n","\n","# Define image dimensions and path to the test directory\n","IMG_HEIGHT = 768  # Change this to your image height\n","IMG_WIDTH = 768   # Change this to your image width\n","TEST_DIR = r'E:/test_v2'  # Use raw string literal for Windows paths\n","\n","# Define a function to load and preprocess test images\n","def load_and_preprocess_image(image_path):\n","    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n","    img = tf.keras.preprocessing.image.img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    img = img / 255.0  # Normalize the image\n","    return img\n","\n","# Define a function to post-process the predicted mask to extract bounding boxes\n","def get_bounding_boxes(prediction, threshold=0.15):\n","    prediction = prediction[0, :, :, 0]  # Extract the single channel\n","    prediction = (prediction > threshold).astype(np.uint8)  # Apply threshold to binarize\n","    contours, _ = cv2.findContours(prediction, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n","    return bounding_boxes\n","\n","# Define a function to display the results\n","def display_results(image_name, test_image, prediction, bounding_boxes):\n","    plt.figure(figsize=(18, 6))\n","    \n","    plt.subplot(1, 3, 1)\n","    plt.title(f'Test Image: {image_name}')\n","    plt.imshow(test_image[0])\n","    \n","    plt.subplot(1, 3, 2)\n","    plt.title('Prediction')\n","    plt.imshow(prediction[0, :, :, 0], cmap='gray')\n","    \n","    plt.subplot(1, 3, 3)\n","    plt.title('Bounding Boxes')\n","    img_with_boxes = (test_image[0] * 255).astype(np.uint8)  # Convert back to uint8\n","    for box in bounding_boxes:\n","        x, y, w, h = box\n","        cv2.rectangle(img_with_boxes, (x, y), (x + w, y + h), (255, 0, 0), 2)\n","    plt.imshow(img_with_boxes)\n","    \n","    plt.show()\n","\n","# Iterate over all images in the test directory and display the results\n","for image_name in os.listdir(TEST_DIR):\n","    image_path = os.path.join(TEST_DIR, image_name)\n","    \n","    # Load and preprocess the test image\n","    test_image = load_and_preprocess_image(image_path)\n","    \n","    # Make a prediction\n","    prediction = resnet50_unet.predict(test_image)\n","    \n","    # Get bounding boxes from the prediction\n","    bounding_boxes = get_bounding_boxes(prediction)\n","    \n","    # Display the test image, predicted mask, and bounding boxes\n","    display_results(image_name, test_image, prediction, bounding_boxes)"]}],"metadata":{"colab":{"collapsed_sections":["EvxPB-mqmFrW","wATcP3FVmFre","75TVsB85mFre","U0tL3mZemFrj"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
